## CLM
Contextual Language Models (CLMs) form the core of RAG 2.0, representing a significant advancement over traditional language models. Unlike standard models that rely solely on pre-trained knowledge, CLMs are designed to dynamically integrate external information during both training and inference
Unlike conventional RAG systems that use separate off-the-shelf components, RAG 2.0 trains all elements - including the embeddings, retriever, and language model - as a single integrated system


## Techniques
- GRIT https://contextual.ai/training-with-grit/https://contextual.ai/training-with-grit/
- KTO https://contextual.ai/better-cheaper-faster-llm-alignment-with-kto/
- LENS https://contextual.ai/introducing-lens/

## Resources
- https://www.perplexity.ai/page/rag-2-0-improved-retrieval-tec-OA0X2PggTBCgZmL0F_FyLA
- https://contextual.ai/introducing-rag2/