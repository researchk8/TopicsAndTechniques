# Prompting

## Components of a Prompt Object

**Instruction**: A fundamental element of any prompt, the instruction is a natural language directive that clearly
describes the task the Language Model (LLM) should perform. This is specified using the instruction variable within the
prompt object.

**Few-Shot Examples**: LLMs are known to perform better when provided with few-shot examples, as they help the model
understand the task context and generate more accurate responses. These examples are specified using the examples
variable in the prompt object. Each example consists of an input and its corresponding output, which the LLM uses to
learn the task.

**Input Model**: Every prompt expects an input to produce an output. In Ragas, the expected format of this input is
defined using the input_model variable. This is a Pydantic model that outlines the structure of the input, enabling
validation and parsing of the data provided to the prompt.

**Output Model**: Upon execution, a prompt generates an output. The format of this output is specified using the
output_model variable in the prompt object. Like the input model, the output model is a Pydantic model that defines the
structure of the output, facilitating validation and parsing of the data produced by the LLM.

## Guidelines for Creating Effective Prompts

When creating prompts, consider the following guidelines to ensure that your prompts are effective and aligned with the
task requirements:

- **Clear and Concise Instructions**: Provide clear and concise instructions that clearly define the task the LLM should
  perform. Ambiguity in instructions can lead to inaccurate responses.
- **Relevant Few-Shot Examples**: Include relevant few-shot examples that cover a diverse range of scenarios related to
  the task (ideally 3-5). These examples help the LLM understand the context and generate accurate responses.
- **Simple Input and Output Models**: Define simple and intuitive input and output models that accurately represent the
  data format expected by the LLM and the output generated by the LLM. If the models are complex, try to break the task
  into smaller sub-tasks with separate prompts.

## Prompt content types

Prompts can include one or more of the following types of content. A prompt can contain any of the following components:

Instruction - a specific task or instruction you want the model to perform

Context - can involve external information or additional context that can steer the model to better responses

Input Data - is the input or question that we are interested to find a response for

Output Indicator - indicates the type or format of the output.

### Input (required)

An input is the text in the prompt that you want the model to provide a response for, and it's a required content type.
Inputs can be a question that the model answers (question input), a task the model performs (task input), an entity the
model operates on (entity input), or partial input that the model completes or continues (completion input).

- question inpu
- task input
- entity input
- completion input

### Context (optional)

### Examples (optional)

## Prompt Design Strategies

Following prompt design strategies:

- Give clear and specific instructions
- Include few-shot examples
- Add contextual information
- Add prefixes
- Let the model complete partial input

## Jailbreaks

Techniques for bypassing restrictions on GPT models.

## Prompt Leaks

Leaked prompts and system information from GPT agents.

## Adversarial Prompting

## Prompt Injection

Exploiting or defending against prompt injections.

## Secure Prompting

Repositories dedicated to securing prompts and mitigating vulnerabilities.

## Prompt Engineering

Prompt engineering is a relatively new discipline for developing and optimizing prompts to efficiently use language
models (LMs) for a wide variety of applications and research topics. Prompt engineering skills help to better understand
the capabilities and limitations of large language models (LLMs). Researchers use prompt engineering to improve the
capacity of LLMs on a wide range of common and complex tasks such as question answering and arithmetic reasoning.
Developers use prompt engineering to design robust and effective prompting techniques that interface with LLMs and other
tools.

# Resources

- https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-intro.md
- https://github.com/trigaten/Learn_Prompting
- https://ai.google.dev/gemini-api/docs/prompting-intro
- https://docs.smith.langchain.com/prompt_engineering/concepts#prompt-canvas
- https://learnprompting.org/docs/vocabulary
- https://github.blog/ai-and-ml/generative-ai/prompt-engineering-guide-generative-ai-llms/
- https://the-decoder.de/der-prompt-report-ist-ein-umfassender-prompting-ueberblick-mit-kuriosen-erkenntnissen/
- https://edcontent.de/content-design/prompting-techniken-chatgpt-cheat-sheet/
- https://learnprompting.org/de/docs/basics/prompting
- https://www.promptingguide.ai/introduction/basics
- https://learn.microsoft.com/en-us/ai-builder/prompts-overview
- https://github.com/VILA-Lab/ATLAS
- https://writings.stephenwolfram.com/2023/06/prompts-for-work-play-launching-the-wolfram-prompt-repository/
- https://github.com/rpidanny/llm-prompt-templates

## Prompt Libraries

- https://docs.anthropic.com/en/prompt-library/library
- https://github.com/danielrosehill/Awesome-LLM-Prompt-Libraries
- https://github.com/CyberAlbSecOP/Awesome_GPT_Super_Prompting
- https://github.com/ai-boost/awesome-prompts
- https://github.com/B3o/GPTS-Prompt-Collection
- https://huggingface.co/datasets/fka/awesome-chatgpt-prompts