# Prompting

## Components of a Prompt Object

**Instruction**: A fundamental element of any prompt, the instruction is a natural language directive that clearly describes the task the Language Model (LLM) should perform. This is specified using the instruction variable within the prompt object.

**Few-Shot Examples**: LLMs are known to perform better when provided with few-shot examples, as they help the model understand the task context and generate more accurate responses. These examples are specified using the examples variable in the prompt object. Each example consists of an input and its corresponding output, which the LLM uses to learn the task.

**Input Model**: Every prompt expects an input to produce an output. In Ragas, the expected format of this input is defined using the input_model variable. This is a Pydantic model that outlines the structure of the input, enabling validation and parsing of the data provided to the prompt.

**Output Model**: Upon execution, a prompt generates an output. The format of this output is specified using the output_model variable in the prompt object. Like the input model, the output model is a Pydantic model that defines the structure of the output, facilitating validation and parsing of the data produced by the LLM.


## Guidelines for Creating Effective Prompts
When creating prompts, consider the following guidelines to ensure that your prompts are effective and aligned with the task requirements:

- **Clear and Concise Instructions**: Provide clear and concise instructions that clearly define the task the LLM should perform. Ambiguity in instructions can lead to inaccurate responses.
- **Relevant Few-Shot Examples**: Include relevant few-shot examples that cover a diverse range of scenarios related to the task (ideally 3-5). These examples help the LLM understand the context and generate accurate responses.
- **Simple Input and Output Models**: Define simple and intuitive input and output models that accurately represent the data format expected by the LLM and the output generated by the LLM. If the models are complex, try to break the task into smaller sub-tasks with separate prompts.

## Techniques
    Zero-shot Prompting
    Few-shot Prompting
    Chain-of-Thought Prompting
    Meta Prompting
    Self-Consistency
    Generate Knowledge Prompting
    Prompt Chaining
    Tree of Thoughts
    Retrieval Augmented Generation
    Automatic Reasoning and Tool-use
    Automatic Prompt Engineer
    Active-Prompt
    Directional Stimulus Prompting
    Program-Aided Language Models
    ReAct
    Reflexion
    Multimodal CoT
    Graph Prompting


See https://www.promptingguide.ai/techniques


## Tools
- https://github.com/mingkaid/rl-prompt (Accompanying repo for the RLPrompt paper)
- https://github.com/Eladlev/AutoPrompt (A framework for prompt tuning using Intent-based Prompt Calibration)
- https://github.com/promptfoo/promptfoo (Test your prompts, agents, and RAGs. Red teaming, pentesting, and vulnerability scanning for LLMs. )
- https://www.promptlayer.com/ (PromptLayer - Maintain a log of your prompts and OpenAI API requests. Track, debug, and replay old completions. )

## Datasets
- https://huggingface.co/datasets/fka/awesome-chatgpt-prompts

## Prompt content types
Prompts can include one or more of the following types of content:

### Input (required)
An input is the text in the prompt that you want the model to provide a response for, and it's a required content type. Inputs can be a question that the model answers (question input), a task the model performs (task input), an entity the model operates on (entity input), or partial input that the model completes or continues (completion input).    

- question inpu 
- task input
- entity input
- completion input


### Context (optional)


### Examples (optional)


## Prompt Design Strategies
Following prompt design strategies:

- Give clear and specific instructions
- Include few-shot examples
- Add contextual information
- Add prefixes
- Let the model complete partial input


# Resources
- https://github.com/trigaten/Learn_Prompting
- https://ai.google.dev/gemini-api/docs/prompting-intro
- https://docs.smith.langchain.com/prompt_engineering/concepts#prompt-canvas
- https://learnprompting.org/docs/vocabulary
- https://github.blog/ai-and-ml/generative-ai/prompt-engineering-guide-generative-ai-llms/
- https://the-decoder.de/der-prompt-report-ist-ein-umfassender-prompting-ueberblick-mit-kuriosen-erkenntnissen/
- https://edcontent.de/content-design/prompting-techniken-chatgpt-cheat-sheet/
- https://learnprompting.org/de/docs/basics/prompting
- https://www.promptingguide.ai/introduction/basics
- https://learn.microsoft.com/en-us/ai-builder/prompts-overview
- https://github.com/VILA-Lab/ATLAS
- https://writings.stephenwolfram.com/2023/06/prompts-for-work-play-launching-the-wolfram-prompt-repository/