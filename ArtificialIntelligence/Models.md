# Models

## Text completion models

## Chat completion models

## Embedding Models
Embedding models are models that are trained specifically to generate vector embeddings: long arrays of numbers that represent semantic meaning for a given sequence of text:
The resulting vector embedding arrays can then be stored in a database, which will compare them as a way to search for data that is similar in meaning.

- all-MiniLM-L6-v2
- mxbai-embed-large
- all-minilm
- nomic-embed-text (Ollama)
- sentence-transformers (Ollama)
- mistral-text-embeddings (Ollama)
- text-embedding-3-large (OpenAI)
- text-ada-002 (OpenAI)

See:
- https://ollama.com/blog/embedding-models

## Factuality checking model
- Bespoke-Minicheck

## Reasoning

### qwq
QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems.

## Code
- codellama

## Image Captions
- BLIP

## Labels - Zero Shot 	
- BART-Large-MNLI

## Labels - Fixed 	
- .

## Summarization
- DistilBART

## Text-to-Speech 	
- ESPnet JETS

## Transcription 	
- Whisper

## Translation 	
- OPUS Model Series

## Vision models
- LLaVA

## Large Language Model (LLM)
- Llama 3.1 Instruct